{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook goes through the following with TensorFlow:\n",
        "\n",
        "- build a transfer learning feature extraction model using TensorFlow Hub\n",
        "- use TensorBoard callback to track and compare model training results"
      ],
      "metadata": {
        "id": "gQc2grv2S2ZE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGQYB29etPrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c18ff05b-45f4-44e3-e1df-8e2144cb2c49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notebook last run (end-to-end): 2024-01-04 18:06:01.153224\n"
          ]
        }
      ],
      "source": [
        "# Add timestamp\n",
        "import datetime\n",
        "print(f\"Notebook last run (end-to-end): {datetime.datetime.now()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if we're using GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNXjUn6nTL63",
        "outputId": "16ab69d8-4402-4401-bfdc-45c91d735870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan  4 18:06:01 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## download data (10% of the food vision data)"
      ],
      "metadata": {
        "id": "DCkMM9N5WbiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Download data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "# Unzip data\n",
        "zip_data = zipfile.ZipFile(\"10_food_classes_10_percent.zip\")\n",
        "zip_data.extractall()\n",
        "zip_data.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlUgZMBlTje0",
        "outputId": "05b51f47-21eb-4a99-cea3-e6a5d0432c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-04 18:06:01--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.161.207, 74.125.126.207, 74.125.132.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.161.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip.2’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M  97.2MB/s    in 1.7s    \n",
            "\n",
            "2024-01-04 18:06:03 (97.2 MB/s) - ‘10_food_classes_10_percent.zip.2’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check data"
      ],
      "metadata": {
        "id": "8CzMzc0LWeTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for root, dirs, files in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are {len(dirs)} directories and {len(files)} images under '{root}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AurmsdyULPd",
        "outputId": "d493872f-e5b8-4d5b-a205-e729aa08a301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images under '10_food_classes_10_percent'.\n",
            "There are 10 directories and 0 images under '10_food_classes_10_percent/train'.\n",
            "There are 0 directories and 75 images under '10_food_classes_10_percent/train/ramen'.\n",
            "There are 0 directories and 75 images under '10_food_classes_10_percent/train/fried_rice'.\n",
            "There are 0 directories and 75 images under '10_food_classes_10_percent/train/pizza'.\n",
            "There are 0 directories and 75 images under '10_food_classes_10_percent/train/chicken_curry'.\n",
            "There are 0 directories and 75 images under '10_food_classes_10_percent/train/steak'.\n",
            "There are 0 directories and 75 images under '10_food_classes_10_percent/train/ice_cream'.\n",
            "There are 0 directories and 75 images under '10_food_classes_10_percent/train/chicken_wings'.\n",
            "There are 0 directories and 75 images under '10_food_classes_10_percent/train/hamburger'.\n",
            "There are 0 directories and 75 images under '10_food_classes_10_percent/train/sushi'.\n",
            "There are 0 directories and 75 images under '10_food_classes_10_percent/train/grilled_salmon'.\n",
            "There are 10 directories and 0 images under '10_food_classes_10_percent/test'.\n",
            "There are 0 directories and 250 images under '10_food_classes_10_percent/test/ramen'.\n",
            "There are 0 directories and 250 images under '10_food_classes_10_percent/test/fried_rice'.\n",
            "There are 0 directories and 250 images under '10_food_classes_10_percent/test/pizza'.\n",
            "There are 0 directories and 250 images under '10_food_classes_10_percent/test/chicken_curry'.\n",
            "There are 0 directories and 250 images under '10_food_classes_10_percent/test/steak'.\n",
            "There are 0 directories and 250 images under '10_food_classes_10_percent/test/ice_cream'.\n",
            "There are 0 directories and 250 images under '10_food_classes_10_percent/test/chicken_wings'.\n",
            "There are 0 directories and 250 images under '10_food_classes_10_percent/test/hamburger'.\n",
            "There are 0 directories and 250 images under '10_food_classes_10_percent/test/sushi'.\n",
            "There are 0 directories and 250 images under '10_food_classes_10_percent/test/grilled_salmon'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalization and create data batches"
      ],
      "metadata": {
        "id": "_Rwm0xcRWW7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization and create data batches\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "train_dir = \"10_food_classes_10_percent/train\"\n",
        "test_dir = \"10_food_classes_10_percent/test\"\n",
        "batch_size = 32\n",
        "img_size = (224, 224)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=img_size,\n",
        "                                               batch_size=batch_size,\n",
        "                                               class_mode=\"categorical\")\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=img_size,\n",
        "                                             batch_size=batch_size,\n",
        "                                             class_mode=\"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lg7G5qAkVRWM",
        "outputId": "69daa0e6-6bd0-4e1f-981e-5120574b884d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 images belonging to 10 classes.\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up TensorBoard callbacks"
      ],
      "metadata": {
        "id": "Hw9E5BB1WTx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks) are extra functionality you can add to your models to be performed during or after training. Some of the most popular callbacks include:\n",
        "\n",
        "- Experiment tracking with TensorBoard - **log the performance** of multiple models and then view and compare these models in a visual way on TensorBoard. Helpful to compare the results of different models on your data.\n",
        "- Model checkpointing - save your model as it trains so you can stop training if needed and come back to continue off where you left. Helpful if training takes a long time and can't be done in one sitting.\n",
        "- Early stopping - leave your model training for an arbitrary amount of time and have it stop training automatically when it ceases to improve. Helpful when you've got a large dataset and don't know how long training will take.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RruuzIfoXO6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a TensorBoard callback"
      ],
      "metadata": {
        "id": "0LtKVP6MYdGQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to save a model's performance logs to a directory named [dir_name]/[experiment_name]/[current_timestamp], where:\n",
        "\n",
        "- dir_name is the overall logs directory\n",
        "- experiment_name is the particular experiment\n",
        "- current_timestamp is the time the experiment started based on Python's datetime.datetime().now()"
      ],
      "metadata": {
        "id": "NR4DvxfHYhW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "  return tensorboard_callback"
      ],
      "metadata": {
        "id": "7Oxxql5KX-9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating models using TensorFlow Hub"
      ],
      "metadata": {
        "id": "FuFFqKmrZRMi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 🤔 **Question:** *I thought we were doing image classification, why do we choose feature vector and not classification?*\n",
        "\n",
        "Differnet types of transfer learning come into play, as is, feature extraction and fine-tuning:\n",
        "\n",
        "- **\"As is\" transfer learning** is when you take a pretrained model as it is and **apply it to your task without any changes**.\n",
        "\n",
        "  * Model's with `\"/classification\"` in their name on TensorFlow Hub provide this kind of functionality.\n",
        "\n",
        "- **Feature extraction transfer learning**: take the weights a pretrained model has learned and **adjust its outputs** to be more suited to your problem.\n",
        "\n",
        "  * For example, say the pretrained model you were using had 236 different layers (EfficientNetB0 has 236 layers), but the top layer outputs 1000 classes because it was pretrained on ImageNet. To adjust this to your own problem, you might remove the original activation layer and replace it with your own but with the right number of output classes. The important part here is that **only the top (last) few layers become trainable, the rest remain frozen**.\n",
        "\n",
        "- **Fine-tuning transfer learning**:  take the weights and **adjust (fine-tune) them** to your own problem.\n",
        "\n",
        "    * This usually means training **some, many or all** of the layers in the pretrained model. This is useful when you've got a large dataset (e.g. 100+ images per class) where your data is slightly different to the data the original model was trained on.\n"
      ],
      "metadata": {
        "id": "95J0bPUxZeev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "OuoBeUUzbHxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_url = \"https://kaggle.com/models/google/resnet-v2/frameworks/TensorFlow2/variations/50-feature-vector/versions/1\"\n",
        "efficientnet_url = \"https://www.kaggle.com/models/google/efficientnet-v2/frameworks/TensorFlow2/variations/imagenet1k-b0-feature-vector/versions/2\""
      ],
      "metadata": {
        "id": "EU-Ko1-vjIPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size+(3,)"
      ],
      "metadata": {
        "id": "LUpV9-UwmmHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "549eb046-f3f0-49c6-eca5-461c575fba9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_with_feature_extraction(weights_url, num_classes=10):\n",
        "  \"\"\"Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n",
        "\n",
        "  Args:\n",
        "    model_url (str): A TensorFlow Hub feature extraction URL.\n",
        "    num_classes (int): Number of output neurons in output layer,\n",
        "      should be equal to number of target classes, default 10.\n",
        "\n",
        "  Returns:\n",
        "    An uncompiled Keras Sequential model with model_url as feature\n",
        "    extractor layer and Dense output layer with num_classes outputs.\n",
        "  \"\"\"\n",
        "  feature_extract_layer = hub.KerasLayer(weights_url,\n",
        "                                         trainable=False,\n",
        "                                         input_shape=img_size+(3,),\n",
        "                                         name=\"feature_extraction_layer\")\n",
        "\n",
        "  model = tf.keras.Sequential([feature_extract_layer,\n",
        "                               layers.Dense(num_classes,\n",
        "                                            name=\"output_layer\",\n",
        "                                            activation=\"softmax\")])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "c3jh561gkbvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = create_model_with_feature_extraction(resnet_url,\n",
        "                                                    train_data.num_classes)\n",
        "\n",
        "resnet_model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=Adam(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "resnet_history=resnet_model.fit(\n",
        "    train_data,\n",
        "    epochs=5,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_data=test_data,\n",
        "    validation_steps=len(test_data),\n",
        "    callbacks=create_tensorboard_callback(\n",
        "        dir_name='tensorflow_hub',\n",
        "        experiment_name='resnet_v2'\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szvexFXblBBI",
        "outputId": "732b33b6-2016-4bd9-d8f9-e500b07b2e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "24/24 [==============================] - 23s 660ms/step - loss: 2.0265 - accuracy: 0.3360 - val_loss: 1.3159 - val_accuracy: 0.5844\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 10s 443ms/step - loss: 0.9218 - accuracy: 0.7173 - val_loss: 0.8718 - val_accuracy: 0.7244\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 11s 472ms/step - loss: 0.6344 - accuracy: 0.8067 - val_loss: 0.7568 - val_accuracy: 0.7676\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 11s 468ms/step - loss: 0.4711 - accuracy: 0.8760 - val_loss: 0.7037 - val_accuracy: 0.7752\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 11s 483ms/step - loss: 0.3808 - accuracy: 0.9133 - val_loss: 0.6787 - val_accuracy: 0.7856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()"
      ],
      "metadata": {
        "id": "FNFvc6S2my3e",
        "outputId": "96368515-c62b-4097-e753-d1d7b8a63719",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " feature_extraction_layer (  (None, 2048)              23564800  \n",
            " KerasLayer)                                                     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23585290 (89.97 MB)\n",
            "Trainable params: 20490 (80.04 KB)\n",
            "Non-trainable params: 23564800 (89.89 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_model = create_model_with_feature_extraction(efficientnet_url,\n",
        "                                                          train_data.num_classes)\n",
        "\n",
        "efficientnet_model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=Adam(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "efficientnet_history = efficientnet_model.fit(\n",
        "    train_data,\n",
        "    epochs=5,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_data=test_data,\n",
        "    validation_steps=len(test_data),\n",
        "    callbacks=create_tensorboard_callback(\n",
        "        dir_name=\"tensorflow_hub\",\n",
        "        experiment_name=\"efficientnet_v2\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN78lBralu8C",
        "outputId": "16d1e6db-0bbe-44d2-9f53-3a9c750e7f05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "24/24 [==============================] - 22s 561ms/step - loss: 2.0171 - accuracy: 0.3387 - val_loss: 1.5481 - val_accuracy: 0.5996\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 10s 436ms/step - loss: 1.3198 - accuracy: 0.6933 - val_loss: 1.1376 - val_accuracy: 0.7064\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 10s 434ms/step - loss: 1.0114 - accuracy: 0.7507 - val_loss: 0.9527 - val_accuracy: 0.7428\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 9s 401ms/step - loss: 0.8417 - accuracy: 0.8067 - val_loss: 0.8599 - val_accuracy: 0.7572\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 10s 433ms/step - loss: 0.7347 - accuracy: 0.8333 - val_loss: 0.8002 - val_accuracy: 0.7672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_model.summary()"
      ],
      "metadata": {
        "id": "GRuyEcNLm1k7",
        "outputId": "e00525e7-2b43-4839-e230-e203a40ac4c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " feature_extraction_layer (  (None, 1280)              5919312   \n",
            " KerasLayer)                                                     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                12810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5932122 (22.63 MB)\n",
            "Trainable params: 12810 (50.04 KB)\n",
            "Non-trainable params: 5919312 (22.58 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}